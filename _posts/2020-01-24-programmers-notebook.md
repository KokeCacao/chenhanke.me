---
title:  "Programmer's Notebook"
categories: 
  - Jekyll
tags:
  - update
---

# Bio
```
Title: Programmer's Notebook
Name: Hanke Chen
Theme: the effect of AI and technology on our society
Audience: graduating upper class highschool students who have common sense
```

Hi, I'm Hanke with an "E." A high school senior who is really interested in building AI-related baubles. I am a typical high school student except I am also the type of nerd who builds robots on Christmas Eve, or codes at a friends' birthday party.
After finished two research reports as a student researcher at X-Order Lab, I am gradually stepping in the Machine Learning research field. I feel empowered to talk about the issues around Artificial Intelligence. The blog "Programmer's Notebook" is how a nerd majoring in Computer Science look at technologies, lives, and our society.

# Post 1 - World Full of Uncertainty: A Discussion of Bias (669 words)
What is bias? When and why do we have biases?

Examples of biases can be found everywhere. [WeChat](https://en.wikipedia.org/wiki/WeChat), a social media app that has almost 900 million users, blamed the use of racial slurs on an error in the artificial intelligence software that translated between English and Chinese. Ann James only noticed it when the [message](www.theguardian.com/world/2017/oct/13/chinas-wechat-app-translates-black-foreigner-to-n-word) "the black foreigner is late" was translated to a message that contains the n-word. Moreover, a paper published on PsyArXiv named "Deep neural networks are more accurate than humans at detecting sexual orientation from facial images" proposed a method to detect people's sexual orientation based only on facial images. Not only could it classify people, but the researchers were also able to generate machines' stereotype of the faces. Was this research biased? This shocking research challenges us to re-think what biases are and where they come from.

To understand where biases come from, let's first look at how machines learn. Nowadays, machines learn from existing data created by humans. The data can be images, text, or your tweeter messages published last Friday. Big technology companies like Google and Facebook are all taking advantage of these human inputs to train their own artificial intelligence to read and understand texts, produce voices, and recommend items on Amazon. When machines get the data, they replicate the way these data are generated. Much like how you learn Spanish: you first replicate adults' sounds before forming your own sentences by generalizing all the sounds you hear from your teacher. Unfortunately, machines' biases are cultivated by our own biased human input. Therefore, in order for machines to be free of bias, we must first be free of biases ourselves. But is it possible?

Is it possible to create a bias-free society? To answer this question, let's investigate how humans learn. Humans learn by practicing. We make mistakes in our childhood and correct them based on the feedbacks presented by adults or the environment. In other words, we use the data generated by our interactions with the environment. Unfortunately, such data is still biased. Why? You can easily recognize hand-written digits when it is written clearly. But don't you ever had a time when you could not recognize someone's handwriting? The judgment of whether handwriting "I" is uppercase "I" or lowercase "L" is highly subjective and therefore biased. Not only for machines, but we also learn using inaccurate data. A bias-free society can only exist in your dream.

Since we cannot prevent biases, can we stop making assumptions? The answer is: "No." Think about the following situation: when you walk into your classroom, you find your seat, sit down, and wait for the bell to ring so that your teacher can appear... well... based on the assumption that the object you sit IS a chair, and the bell WILL ring eventually, and your teacher WANTS to teach you today, etc... Whenever we perform an action, there are a limitless number of assumptions we use subconsciously, and therefore assumptions are essential to lives. Such intuition of making assumptions all the time might come from evolutional psychology: imagine there is a lion chasing you. Should you run assuming it is a real lion, or stop to observe the lion in detail to figure out whether it is more likely to be a mad big-cat before you end up in the lion's stomach? That's bad, isn't it: we are biased, and we cannot stop making assumptions.

You might ask: is there a way to improve our current situation? Yes, there is. Education and standardization is the best way to make our mind "less biased," by making judgments more objective, which is why the constitution, charters, and scientific laws exist. Ultimately, removing a bias doesn't necessarily make a judgment "more right," but it prevents conflicts and misinterpretations in languages and actions.

How can we live in a world full of uncertainty and bias? Thoughts?

# Post 2 - Death by AI: The Future Politics (705 words)
January. 3 2020, Trump, representing the United State of America, assassinated Suleimani using a drone strike. Set aside all the political significance and interpretations posted by the media, let's discuss the impacts of future technology on politics.

[YouTube](https://www.youtube.com/watch?v=9CO6M2HsoIA)

Although the drone strike on Jan.3 was not actually related to Artificial Intelligence at all, the idea of AI-assisted drone strikes is not new. Short documentaries like "Slaughterbot" (recommended to watch if you have not) directed by Stewart Sugg criticized the use of AI-assisted drones as a weapon to precisely kill the criminals. In the video, a $25 million order of drones could easily kill half a city without destroying the infrastructure. Given its efficiency and low-cost, these imaginative AI-assisted weapons are likely to be the next alternatives for nuclear weapons.

There are consequences of AI-assisted drone technology. After the technology reaches its maturity, powerful countries like the U.S., China, Russia, Germany, and Japan will ban automatic drone-killers that pretty much represent the future warfare to protect the effectiveness of established deterrence. Such bans on national security technology, like nuclear weapons, will destroy the balance of power between nations, thus suppress the development of weaker countries. Why do you think Iran and North Korea need nuclear weapons? It's not because they want to kill all people on Earth, but doing so gives them a voice in diplomacy. It's the same situation as all 12-graders have guns in their pocket and promise not to use it while trying to report freshmen who have any intention of making a small pistol. Facing such a nuclear monopoly, it's helpless, but that's not it!

Even within the country, the future of the presidential elections could well depend on AI-related algorithms. In fact, I can already see a sign of how computer science played a big role in our last presidential election. The Democratic Party and the Republican Party used mass advertisement along with Cybersecurity technology to protect their candidates and to attack their opponents. The Hillary Clinton email controversy and Trump-Ukraine scandal both demonstrated the effectiveness of hacking to gain the trust of the voters. Besides controlling the opponents, AI-related technology will control the voters.

These technological manipulations in the presidential election might have a huge effect on our democracy. In terms of getting people's trust, AI is and will still be much better than any individual. The AI-assisted recommender system, commonly used in search engines and popular social media like TikTok, will be adapted as a weapon to gain political trusts of the voters. In another word, the politicians will implement the same recommender system that pushes you Youtube videos online, to make sure what you will hear is what you want to hear. Even a high school student like me can now develop an algorithm that detects emotions in Twitter languages, not to mention how the political parties will make use of such tools to predict the political climate in the future.

By collecting data generated by the user's activities from Facebook or Twitter, politicians can accurately predict the political climate. People usually underestimate the effectiveness of controlling the political climate in presidential elections. But imagine this situation: if you twit about your lesbian friend's unfair treatments in schools, would you not support a candidate who pushes for LGBT+ rights? If you complain about your low wage on Twitter, would you not vote for a candidate who promises an economic reform to "Make America Great Again"? If you can't find a job, would you be willing to advocate for a candidate who blames the "illegal immigrants" for taking all the jobs? Twitter messages become meaningful when such complaints become a trend that spreads around the country within 1~2 days. The detection of emotions on social media berries a huge treasure for candidates to change their strategy and to speak to voters on individual bases.

Building an emotion-predictive AI model is easy, but the accuracy of such a model largely depends on the data available. Because AI models are data-driven algorithms, candidates who are willing to invest in collecting BigData are pretty much guaranteed to build a better predictive model. Eventually, the future race of the presidential election will become a race to build the best AI model, and therefore, a race of wealth.

For animals, stronger means speed or muscles. For humans, stronger means equipping ourselves with powerful tools of technology. What do you think the future will be like? Comments?

