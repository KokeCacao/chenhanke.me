---
title: "Academic / AI Research"
permalink: /academic/
excerpt: ""
layouts_gallery:
  - url: /assets/images/mm-layout-splash.png
    image_path: /assets/images/mm-layout-splash.png
    alt: "splash layout example"
  - url: /assets/images/mm-layout-single-meta.png
    image_path: /assets/images/mm-layout-single-meta.png
    alt: "single layout with comments and related posts"
  - url: /assets/images/mm-layout-archive.png
    image_path: /assets/images/mm-layout-archive.png
    alt: "archive layout example"
last_modified_at: 2019-04-03T15:15:09-04:00
toc: false
cell:
  - image_path: https://www.youtube-nocookie.com/embed/bcU--nlPIRM?autoplay=1&mute=1&showinfo=0&rel=0&loop=1&playlist=bcU--nlPIRM
    excerpt: '**Video: Report Presentation**<br/>---<br/>Time: `2018`<br/>Achievements: `Model Prediction Accuracy 63.07%`<br/><br/> >> I implemented a Convolution Neural Network with Residue and Squeeze-Excitation layers classifier to locate given proteins of any type in a subcellular structure. After training the model using a series of techniques, it can locate thousands of proteins in 27 different human cell types into 28 subcellular locations, way significant than historical approaches. The model can classify 4,500 images per minute with an accuracy of 63.07%, surpassing human performance in accuracy (by 35%) and speed.'
    url: https://www.googlesciencefair.com/projects/2018/f8a2584ecc30ea734d38042a861db599f14dd9a8fb0618b1bb10c480e7dc13b8
    btn_label: "Read Report"
    btn_class: "btn--primary"
    section_name: "0"
bike:
  - image_path: /assets/images/nail9.jpg
    excerpt: '**Image: Predicted Trend vs. Real Trend**<br/>---<br/>Time: `2017`<br/>Achievements: `Model Prediction Accuracy 80.3%`<br/><br/> >> I used a simple feed forward Neuron Network to predict the hourly amount usage of shared bikes using features like the season, weather, and date.'
    url: /assets/html/Your_first_neural_network.html
    btn_label: "See Project"
    btn_class: "btn--primary"
    section_name: "0"
dog:
  - image_path: /assets/images/nail11.jpg
    excerpt: '**Image: Digits and Faces generated by my code**<br/>---<br/>Time: `2017`<br/>Achievements: `Generated Human-recognizable faces` `Generated handwriting digits`<br/><br/> >> In this project, I detected the types of dogs using Convolutional Neutron Network. I first loaded the human face dataset from scikit-learn and detect faces as a practice. After training the dataset using ResNet50 architecture, I found out that the pre-trained model can out-compete the performance of OpenCV library by about 10% accuracy. Then went a step further to predict the types of dogs using CNN and trained it from scratch. Although the accuracy of standard CNN is low (9.2% accuracy), but with ResNet50 architecture, I was able to successfully classify 41.5% of the dogs into 133 correct categories, way better than my performance.'
    url: /assets/html/dog_app_zh.html
    btn_label: "See Project"
    btn_class: "btn--primary"
    section_name: "0"
face:
  - image_path: /assets/images/nail12.jpg
    excerpt: '**Image: Predicted Trend vs. Real Trend**<br/>---<br/>Time: `2017`<br/>Achievements: `Generating Human-recognizable Pictures`<br/><br/> >> I generated handwritten digits pictures and faces using GAN on MNIST and CelebA dataset. After data pre-processing and building the Generator and Discriminator, I trained the GAN and fine-tuned the parameters. The parameters(learning rates) are hard to tune but after only one epoch, the network can output recognizable handwritings and faces completely generated by computer from random numbers.'
    url: /assets/html/dlnd_face_generation-zh.html
    btn_label: "See Project"
    btn_class: "btn--primary"
    section_name: "0"
script:
  - image_path: /assets/images/nail13.jpg
    excerpt: '**Image: novel/TV script generated by my code**<br/>---<br/>Time: `2017`<br/>Achievements: `Generated Human-recognizable novel`<br/><br/> >> Using Recursive Neuron Network I generated TV Scripts for "The Simpsons". I first tokenize each word in The Simpsons Dataset and use Tensorflow to train the embedded words in mini-batches. After 124 epochs, the model can generate some scripts that actually make some sense.'
    url: /assets/html/dlnd_tv_script_generation-zh.html
    btn_label: "See Project and Generated Scripts"
    btn_class: "btn--primary"
    section_name: "0"
drone:
  - image_path: /assets/images/nail10.jpg
    excerpt: '**Image: tragectory of fully-automatic drone in simulation**<br/>---<br/>Time: `2017`<br/>Achievements: `Using RL to balance the drones` `Command the drone to go to specific coordinate`<br/><br/> >> In this project, I was able to make a virtual drone dynamically hover and go to a specific location its own using Reinforcement Learning. Usually, people have to control four different motors to ensure drones do not crash, but now with this algorism, you can tell a drone x,y,z where it should go and it can go there automatically.'
    url: /assets/html/Quadcopter_Project_zh.html
    btn_label: "See Project"
    btn_class: "btn--primary"
    section_name: "0"
cancer:
  - image_path: /assets/images/nail2.jpg
    excerpt: '**Image: Predicted Trend vs. Real Trend**<br/>---<br/>Time: `2019`<br/>Achievements: `97.82% AUC score` `1st Ranked on Public Leaderboard (Top 1%)` `113rd Ranked on Private Leaderboard (Top 10%)`<br/><br/> >> In this Kaggle Competition, I use neuron-network to detect cancer samples from histopathologic images with unbelieveable 98% accuracy, surpassing the accuracy of PatchCamelyon benchmark model in the paper `B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling. "Rotation Equivariant CNNs for Digital Pathology". arXiv:1806.03962` (AUC 96.3%). Although people cheated using the method I discovered in the competition, I was still ranked TOP 10% with my hardwork.'
    url: "https://www.kaggle.com/c/histopathologic-cancer-detection/discussion/87367"
    btn_label: "See Technical Detail"
    btn_class: "btn--primary"
    section_name: "0"
imet:
  - image_path: /assets/images/nail2.jpg
    excerpt: 'No information so far because I am currently competiting in this competition'
    url: ...
    btn_label: "..."
    btn_class: "btn--primary"
    section_name: "0"
gratification:
  - image_path: /assets/images/nail2.jpg
    excerpt: 'No information so far because I am currently competiting in this competition'
    url: ...
    btn_label: "..."
    btn_class: "btn--primary"
    section_name: "0"
siim:
  - image_path: /assets/images/nail2.jpg
    excerpt: 'No information so far because I am currently competiting in this competition'
    url: ...
    btn_label: "..."
    btn_class: "btn--primary"
    section_name: "0"
---
{% include box height="8px" color="b7ba53" %}
The motivation of learning AI to me is that it can be used in many fields. "It is only a tool," I thought so. But later I realize that the theory of training neuron networks can be used to human learning too. "The biggest benefit that AI brought to us is not only a strong algorism but also the theory of learning."

The interests of wanting to know the fundamental mechanism of AI drove me into Udacity's Machine Learning online course. In 1.5 years, I graduated from Machine Learning (Basics) and Deep Learning (Advanced) Nanodegrees. Although these knowledge are too basic compared to tricks used in Kaggle competitions, these courses introduced me to a group of alumni and dragged me into the AI research coterie.
Three years before, I started with nothing. But now I ended up competing with other AI researchers as a high school student.

Here are some projects I did as I gradually enter the fields of AI.
{% include box height="8px" color="b7ba53" %}

---
# Google Science Fair: Extracting Cellular Location of Human Proteins Using Deep Learning
---
{% include feature_row id="cell" type="left" %}
{: .notice--success}
---
# Predicting the Usage of Shared Bikes Using Neuron Networks (NN)
---
{% include feature_row id="bike" type="left" %}
{: .notice--success}
---
# Detecting Dogs Using Convolutional Neuron Networks (CNN)
---
{% include feature_row id="dog" type="left" %}
{: .notice--success}
---
# Generating Faces Using Generative Adverserial Networks (GAN)
---
{% include feature_row id="face" type="left" %}
{: .notice--success}
---
# Generating TV Scripts Using Recurrent Neural Networks (RNN)
---
{% include feature_row id="script" type="left" %}
{: .notice--success}
---
# Teaching Drones to Fly Using Reinforcement Learning (RL)
---
{% include feature_row id="drone" type="left" %}
{: .notice--success}
---
# Kaggle: Histopathologic Cancer
---
{% include feature_row id="cancer" type="left" %}
{: .notice--success}
---
# Kaggle: IMet Collection
---
{% include feature_row id="imet" type="left" %}
{: .notice--success}
---
# Kaggle: Instant Gratification
---
{% include feature_row id="gratification" type="left" %}
{: .notice--success}
---
# Kaggle: SIIM-ACR Pneumothorax Segmentation
---
{% include feature_row id="siim" type="left" %}
{: .notice--success}